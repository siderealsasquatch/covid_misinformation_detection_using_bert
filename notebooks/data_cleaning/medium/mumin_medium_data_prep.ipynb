{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fdf5d9-58b5-4331-bc3b-98051cddfe87",
   "metadata": {},
   "source": [
    "# MuMiN large data preparation\n",
    "\n",
    "In this notebook we will process the MuMiN large dataset in the following way:\n",
    "\n",
    "- Extract the tweet text, label and language\n",
    "- Perform basic text cleaning\n",
    "- Translate the tweet texts into Bahasa Indonesia\n",
    "- Create the training, test, and validation splits\n",
    "\n",
    "Note that since we only care about the tweet text, we will be omitting images and articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c74dc-980b-45a1-861e-3d0f62a7540c",
   "metadata": {},
   "source": [
    "# Extract necessary features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a82a528-8f87-4a43-8486-9ae28939dcb0",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9801dd7d-5aab-4e8c-8163-6b2d3042b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahmi/.conda/envs/ml-general/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/fahmi/.conda/envs/ml-general/lib/python3.10/site-packages/mumin/dataset.py:176: UserWarning: Twitter bearer token not provided, so rehydration can not be performed. This is fine if you are using a pre-compiled MuMiN, but if this is not the case then you will need to either specify the `twitter_bearer_token` argument or set the environment variable `TWITTER_API_KEY`.\n",
      "  warnings.warn('Twitter bearer token not provided, so '\n",
      "2022-07-28 20:26:35,765 [INFO] Loading dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MuminDataset(num_nodes=805,586, num_relations=1,061,640, size='medium', compiled=True, bearer_token_available=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from mumin import MuminDataset\n",
    "\n",
    "# Set file names and paths\n",
    "data_dir = Path(\"../../data/mumin_archive\")\n",
    "dataset_file = \"mumin-medium_no-images.zip\"\n",
    "\n",
    "# Load the compiled dataset\n",
    "size = \"medium\"\n",
    "dataset_path = data_dir.joinpath(dataset_file)\n",
    "include_tweet_images = False\n",
    "include_articles = False\n",
    "dataset = MuminDataset(dataset_path=dataset_path, size=size, include_tweet_images=include_tweet_images, include_articles=include_articles)\n",
    "dataset.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458b32d-f853-44be-be2f-48c9be0d2225",
   "metadata": {},
   "source": [
    "## Join claims with their tweets\n",
    "\n",
    "Since we're focusing on COVID-19 misinformation, we will first filter out the claims that aren't about COVID-19 before joining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c01b304-eb3c-4556-919d-0715c32b76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_204252/320260173.py:7: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  covid_mask = claims.keywords.str.contains('(corona(.*virus)?|covid(.*19)?)') | claims.cluster_keywords.str.contains('(corona(.*virus)?|covid(.*19)?)')\n"
     ]
    }
   ],
   "source": [
    "# Get tweets, claims and the relations between them\n",
    "tweets = dataset.nodes[\"tweet\"].dropna()\n",
    "claims = dataset.nodes[\"claim\"]\n",
    "rels = dataset.rels[(\"tweet\", \"discusses\", \"claim\")]\n",
    "\n",
    "# Filter claims\n",
    "covid_mask = claims.keywords.str.contains('(corona(.*virus)?|covid(.*19)?)') | claims.cluster_keywords.str.contains('(corona(.*virus)?|covid(.*19)?)')\n",
    "claims_filtered = claims.loc[covid_mask, :]\n",
    "\n",
    "# Join tweets and claims on rels\n",
    "tc = (tweets.merge(rels, left_index=True, right_on='src')\n",
    "            .merge(claims_filtered, left_on='tgt', right_index=True)\n",
    "            .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2920030c-59a0-4d6e-8470-19f70e887131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4483 entries, 0 to 4482\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   tweet_id          4483 non-null   uint64        \n",
      " 1   text              4483 non-null   object        \n",
      " 2   created_at        4483 non-null   datetime64[ns]\n",
      " 3   lang              4483 non-null   category      \n",
      " 4   source            4483 non-null   object        \n",
      " 5   num_retweets      4483 non-null   uint64        \n",
      " 6   num_replies       4483 non-null   uint64        \n",
      " 7   num_quote_tweets  4483 non-null   uint64        \n",
      " 8   src               4483 non-null   int64         \n",
      " 9   tgt               4483 non-null   int64         \n",
      " 10  embedding         4483 non-null   object        \n",
      " 11  label             4483 non-null   category      \n",
      " 12  reviewers         4483 non-null   object        \n",
      " 13  date              4483 non-null   datetime64[ns]\n",
      " 14  language          4483 non-null   category      \n",
      " 15  keywords          4483 non-null   object        \n",
      " 16  cluster_keywords  4483 non-null   category      \n",
      " 17  cluster           4483 non-null   category      \n",
      " 18  train_mask        4483 non-null   bool          \n",
      " 19  val_mask          4483 non-null   bool          \n",
      " 20  test_mask         4483 non-null   bool          \n",
      "dtypes: bool(3), category(5), datetime64[ns](2), int64(2), object(5), uint64(4)\n",
      "memory usage: 491.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db063177-f56a-4726-816d-f0e4b42a7ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>num_retweets</th>\n",
       "      <th>num_replies</th>\n",
       "      <th>num_quote_tweets</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>...</th>\n",
       "      <th>label</th>\n",
       "      <th>reviewers</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cluster_keywords</th>\n",
       "      <th>cluster</th>\n",
       "      <th>train_mask</th>\n",
       "      <th>val_mask</th>\n",
       "      <th>test_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1243046281326534661</td>\n",
       "      <td>To keep our upper respiratory tract healthy in...</td>\n",
       "      <td>2020-03-26 05:25:02</td>\n",
       "      <td>en</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243148522209161217</td>\n",
       "      <td>Gargling salt water does not 'kill' coronaviru...</td>\n",
       "      <td>2020-03-26 12:11:18</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1238795119572049920</td>\n",
       "      <td>‡§ï‡•â‡§∞‡•ã‡§®‡§æ ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§´‡•á‡§´‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§§‡•Ä‡§®-‡§ö‡§æ‡§∞ ...</td>\n",
       "      <td>2020-03-14 11:52:26</td>\n",
       "      <td>hi</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1238947475471454220</td>\n",
       "      <td>Antes de llegar a los pulmones dura 4 d√≠as en ...</td>\n",
       "      <td>2020-03-14 21:57:51</td>\n",
       "      <td>es</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239128401115516929</td>\n",
       "      <td>So they say the first symptons are #coughing\\n...</td>\n",
       "      <td>2020-03-15 09:56:47</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1243046281326534661  To keep our upper respiratory tract healthy in...   \n",
       "1  1243148522209161217  Gargling salt water does not 'kill' coronaviru...   \n",
       "2  1238795119572049920  ‡§ï‡•â‡§∞‡•ã‡§®‡§æ ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§´‡•á‡§´‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§§‡•Ä‡§®-‡§ö‡§æ‡§∞ ...   \n",
       "3  1238947475471454220  Antes de llegar a los pulmones dura 4 d√≠as en ...   \n",
       "4  1239128401115516929  So they say the first symptons are #coughing\\n...   \n",
       "\n",
       "           created_at lang               source  num_retweets  num_replies  \\\n",
       "0 2020-03-26 05:25:02   en       Hootsuite Inc.            96            6   \n",
       "1 2020-03-26 12:11:18   en   Twitter for iPhone             7            0   \n",
       "2 2020-03-14 11:52:26   hi  Twitter for Android             6            0   \n",
       "3 2020-03-14 21:57:51   es  Twitter for Android             8            3   \n",
       "4 2020-03-15 09:56:47   en  Twitter for Android            10            2   \n",
       "\n",
       "   num_quote_tweets  src  tgt  ...           label        reviewers  \\\n",
       "0                 6    0    0  ...  misinformation  [observador.pt]   \n",
       "1                 0    1    0  ...  misinformation  [observador.pt]   \n",
       "2                 1    2    0  ...  misinformation  [observador.pt]   \n",
       "3                 0    3    0  ...  misinformation  [observador.pt]   \n",
       "4                 1    4    0  ...  misinformation  [observador.pt]   \n",
       "\n",
       "                 date language                             keywords  \\\n",
       "0 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "1 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "2 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "3 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "4 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "\n",
       "                                    cluster_keywords cluster train_mask  \\\n",
       "0  coronavirus china covid 19 treatments recommended       0       True   \n",
       "1  coronavirus china covid 19 treatments recommended       0       True   \n",
       "2  coronavirus china covid 19 treatments recommended       0       True   \n",
       "3  coronavirus china covid 19 treatments recommended       0       True   \n",
       "4  coronavirus china covid 19 treatments recommended       0       True   \n",
       "\n",
       "   val_mask  test_mask  \n",
       "0     False      False  \n",
       "1     False      False  \n",
       "2     False      False  \n",
       "3     False      False  \n",
       "4     False      False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4933b-0b1b-496c-a569-a575f5fad1e5",
   "metadata": {},
   "source": [
    "## Get the necessary features\n",
    "\n",
    "Here we extract the following features:\n",
    "\n",
    "- `text`\n",
    "- `label`\n",
    "- `lang`\n",
    "\n",
    "We don't need any of the `*mask` columns since we're going to create our own splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87047ad2-265b-4cce-a5ad-ff360a194860",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"text\", \"label\", \"lang\"]\n",
    "dataset_clean = tc[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b821be",
   "metadata": {},
   "source": [
    "## Remove records with `zxx` language code\n",
    "\n",
    "We'll remove all records with the `zxx` language code as it stands for \"no linguistic content\". If we actually look at the records with this language code, it's clear that they are all URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b74da9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>https://t.co/DIOtokZ5JZ</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>https://t.co/zwKqF4qur7</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>https://t.co/HeZ2S7sk5o</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>https://t.co/ds4fqa6FiK</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>https://t.co/xI5YfL0DBu</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>https://t.co/xI5YfL0DBu</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>https://t.co/xI5YfL0DBu</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>https://t.co/QRB1suNRA4</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>https://t.co/QRB1suNRA4</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>https://t.co/QRB1suNRA4</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>https://t.co/vJW7Zt3pHv</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>https://t.co/vJW7Zt3pHv</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>https://t.co/Q4x0mHT4im</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>https://t.co/DOABphhTgr</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>https://t.co/CmMZLUY0IE</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>https://t.co/UE0bWfM51E</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>https://t.co/br0jHLXvbB</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>https://t.co/DOABphhTgr</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>https://t.co/CmMZLUY0IE</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>https://t.co/UE0bWfM51E</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>https://t.co/br0jHLXvbB</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>https://t.co/DOABphhTgr</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>https://t.co/CmMZLUY0IE</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>https://t.co/UE0bWfM51E</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>https://t.co/br0jHLXvbB</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>https://t.co/jwd392iz4q</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>https://t.co/jwd392iz4q</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>https://t.co/Ge93Q236Pd</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>https://t.co/cP4UdTAkEn</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>https://t.co/9R2TgCzoke</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>zxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text           label lang\n",
       "236   https://t.co/DIOtokZ5JZ  misinformation  zxx\n",
       "349   https://t.co/zwKqF4qur7  misinformation  zxx\n",
       "546   https://t.co/HeZ2S7sk5o  misinformation  zxx\n",
       "772   https://t.co/ds4fqa6FiK  misinformation  zxx\n",
       "1060  https://t.co/xI5YfL0DBu  misinformation  zxx\n",
       "1068  https://t.co/xI5YfL0DBu  misinformation  zxx\n",
       "1074  https://t.co/xI5YfL0DBu  misinformation  zxx\n",
       "1685  https://t.co/QRB1suNRA4  misinformation  zxx\n",
       "1686  https://t.co/QRB1suNRA4  misinformation  zxx\n",
       "1687  https://t.co/QRB1suNRA4  misinformation  zxx\n",
       "1860  https://t.co/vJW7Zt3pHv  misinformation  zxx\n",
       "1864  https://t.co/vJW7Zt3pHv  misinformation  zxx\n",
       "1934  https://t.co/Q4x0mHT4im  misinformation  zxx\n",
       "1973  https://t.co/DOABphhTgr  misinformation  zxx\n",
       "1975  https://t.co/CmMZLUY0IE  misinformation  zxx\n",
       "1982  https://t.co/UE0bWfM51E  misinformation  zxx\n",
       "1988  https://t.co/br0jHLXvbB  misinformation  zxx\n",
       "1989  https://t.co/DOABphhTgr  misinformation  zxx\n",
       "1991  https://t.co/CmMZLUY0IE  misinformation  zxx\n",
       "1998  https://t.co/UE0bWfM51E  misinformation  zxx\n",
       "2004  https://t.co/br0jHLXvbB  misinformation  zxx\n",
       "2005  https://t.co/DOABphhTgr  misinformation  zxx\n",
       "2007  https://t.co/CmMZLUY0IE  misinformation  zxx\n",
       "2010  https://t.co/UE0bWfM51E  misinformation  zxx\n",
       "2013  https://t.co/br0jHLXvbB  misinformation  zxx\n",
       "2642  https://t.co/jwd392iz4q  misinformation  zxx\n",
       "2644  https://t.co/jwd392iz4q  misinformation  zxx\n",
       "2684  https://t.co/Ge93Q236Pd  misinformation  zxx\n",
       "3580  https://t.co/cP4UdTAkEn  misinformation  zxx\n",
       "3612  https://t.co/9R2TgCzoke  misinformation  zxx"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all records with \"zxx\" language code\n",
    "dataset_clean.loc[dataset_clean.lang == \"zxx\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e3906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all records with \"zxx\" language code\n",
    "dataset_clean = dataset_clean.loc[~(dataset_clean.lang == \"zxx\"), :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457a72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the current state of the dataset to a csv file\n",
    "# Note that this is just a temporary code block\n",
    "outfile = \"mumin_medium-raw.csv\"\n",
    "dataset_clean.to_csv(Path(\"data\").joinpath(outfile), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c675ed-2e76-4e1a-83f1-2cf4b40b4398",
   "metadata": {},
   "source": [
    "# Clean dataset\n",
    "\n",
    "Here we perform only the following operations:\n",
    "\n",
    "- Encode the labels\n",
    "- Translate the text\n",
    "- Substitute URLs, mentions, and (maybe) hashtags with an indicative token\n",
    "- Remove emojis\n",
    "- Normalize whitespace\n",
    "- Remove any other unnecessary characters that I happen to notice\n",
    "\n",
    "All of the more in-depth text cleaning operations will be done once the text has been translated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0591032-42f4-4ba9-99f8-32d0b1bdf2a6",
   "metadata": {},
   "source": [
    "## Encode labels\n",
    "\n",
    "Here we encode the labels in the following way:\n",
    "\n",
    "- `misinformation`: 1\n",
    "- `factual`: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d8cf923-f3eb-4daf-958a-cf9d4954ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\4140734251.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_clean.label.replace(to_replace=encodings, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "encodings = {\"misinformation\": 1, \"factual\": 0}\n",
    "dataset_clean.label.replace(to_replace=encodings, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c684bbf2-2c10-4a81-8139-cdb2946e0f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17625\n",
       "0      600\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ae201-4190-4f8f-a796-a6f2d03984d8",
   "metadata": {},
   "source": [
    "## Remove URLs and mentions\n",
    "\n",
    "Not sure if we should completely remove URLS and mentions as both provide useful information. For now, I'll simply replace URLs with `<URL>` and mentions with `<USER>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1f1e7c4-da7c-4fd5-80dd-8cd44213c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"http\\S+\", \"<URL>\")\n",
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"http\\S+\", \"<URL>\")\n",
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"@\\S+\", \"<USER>\")\n",
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"@\\S+\", \"<USER>\")\n"
     ]
    }
   ],
   "source": [
    "dataset_clean.text = dataset_clean.text.str.replace(\"http\\S+\", \"<URL>\")\n",
    "dataset_clean.text = dataset_clean.text.str.replace(\"@\\S+\", \"<USER>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ffe8eb-21fe-4c72-8dbf-9d07a97a7722",
   "metadata": {},
   "source": [
    "## Remove whitespace literal characters\n",
    "\n",
    "Here we remove stray newline and tab characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15bd34e9-ac42-4cb9-95c1-fb569975fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\876289396.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_test = dataset_clean.text.str.replace(r\"\\n|\\t\", \"\").str.replace(\"|\", \"\", regex=False).str.replace(\"\\s+\", \" \")\n"
     ]
    }
   ],
   "source": [
    "text_test = dataset_clean.text.str.replace(r\"\\n|\\t\", \"\").str.replace(\"|\", \"\", regex=False).str.replace(\"\\s+\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29fa2bcb-6384-4c92-9005-7287f3c23f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"To keep our upper respiratory tract healthy in this time of #coronavirus, let's all gargle warm water with salt (preferably himalayan or sea salt), some ginger and apple cider vinegar first thing in the morning and before we sleep. Spit the water out after. #LetsFightCovid19 <URL>\",\n",
       " \"Gargling salt water does not 'kill' coronavirus in your throat Metro News <URL>\",\n",
       " '‡§ï‡•â‡§∞‡•ã‡§®‡§æ ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§´‡•á‡§´‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§§‡•Ä‡§®-‡§ö‡§æ‡§∞ ‡§¶‡§ø‡§® ‡§§‡§ï ‡§ó‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§π‡•à...‡§â‡§∏‡§∏‡•á ‡§ñ‡§æ‡§Ç‡§∏‡•Ä ‡§µ ‡§ï‡§´ ‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§≠‡•Ä ‡§∞‡§π‡§§‡•Ä ‡§π‡•à...‡§ê‡§∏‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§Ö‡§ó‡§∞ ‡§ó‡§∞‡•ç‡§Æ ‡§™‡§æ‡§®‡•Ä ‡§Æ‡•á‡§Ç ‡§®‡§Æ‡§ï ‡§°‡§æ‡§≤‡§ï‡§∞ ‡§ó‡§∞‡§æ‡§∞‡•á ‡§ï‡§ø‡§è ‡§ú‡§æ‡§è‡§Ç...‡§î‡§∞ ‡§®‡•Ä‡§Ç‡§¨‡•Ç ‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§è ‡§§‡•ã ‡§á‡§∏ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§¨‡§ö‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à...‡§î‡§∞ ‡§Ö‡§®‡•á‡§ï‡•ã‡§Ç ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä ‡§¨‡§ö ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§üïâÔ∏èüëãüå∑üåπüíêüå¥ <URL>',\n",
       " 'Antes de llegar a los pulmones dura 4 d√≠as en la garganta, en ese punto la persona infectadas empiezan a toser y a tener dolor de garganta. Deben tomar mucha agua y hacer g√°rgaras de agua tibia con sal o vinagre esto eliminar√° el CORONAVIRUS retuitear pues pueden salvar alguien. <URL>',\n",
       " 'So they say the first symptons are #coughingThe virus stays in your throat for 4 days and that you can kill it by drinking hot liquids.. Tea, soup etc#coronavirus #COVID„Éº19 <URL>']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test.to_list()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8f689-3b7b-49df-8677-fe5d2f438631",
   "metadata": {},
   "source": [
    "## Remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c85062-5916-4417-9e3e-5905d412f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = dataset_clean.text.str.encode(\"ascii\", \"ignore\").str.decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6515bbd-b72b-46e7-80b3-dcaae4fbaedc",
   "metadata": {},
   "source": [
    "## Remove other unnecessary characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b807b-1180-4156-a6d3-0970793fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.text = dataset_clean.text.str.replace(\"|\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a046cc5-a5a2-455c-bc47-109aae59d027",
   "metadata": {},
   "source": [
    "## Remove excess whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680cc83-918c-47f1-bec7-06b00d51062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.text = dataset_clean.text.str.replace(\"\\s+\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b236ba-379c-423d-8cab-e774eda67e95",
   "metadata": {},
   "source": [
    "# Translate text\n",
    "\n",
    "This will be done later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af965b-f89d-4eba-94dd-1ea4582ccfc8",
   "metadata": {},
   "source": [
    "# Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "949588cb-e0f0-465b-a965-aa25f44c22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits\n",
    "train = dataset_clean.query('train_mask == True')\n",
    "val = dataset_clean.query('val_mask == True')\n",
    "test = dataset_clean.query('test_mask == True')\n",
    "\n",
    "# Write them to csv files\n",
    "features = [\"text\", \"label\", \"lang\"]\n",
    "output_files = [\"mumin_large-train.csv\", \"mumin_large-test.csv\", \"mumin_large-validation.csv\"]\n",
    "splits = [train, test, val]\n",
    "for split, output_file in zip(splits, output_files):\n",
    "    split.to_csv(data_dir.joinpath(output_file), columns=features, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml-general')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5601624226c7fabf755c65c27496246b0957db3b04a656cd3f1a6ab210a58a54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
