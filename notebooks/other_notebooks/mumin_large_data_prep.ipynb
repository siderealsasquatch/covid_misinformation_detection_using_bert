{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fdf5d9-58b5-4331-bc3b-98051cddfe87",
   "metadata": {},
   "source": [
    "# MuMiN large data preparation\n",
    "\n",
    "In this notebook we will process the MuMiN large dataset in the following way:\n",
    "\n",
    "- Extract the tweet text, label and language\n",
    "- Perform basic text cleaning\n",
    "- Translate the tweet texts into Bahasa Indonesia\n",
    "- Create the training, test, and validation splits\n",
    "\n",
    "Note that since we only care about the tweet text, we will be omitting images and articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c74dc-980b-45a1-861e-3d0f62a7540c",
   "metadata": {},
   "source": [
    "# Extract necessary features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a82a528-8f87-4a43-8486-9ae28939dcb0",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9801dd7d-5aab-4e8c-8163-6b2d3042b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\scoop\\apps\\miniconda3\\current\\envs\\ml-general\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-07-06 11:22:46,995 [INFO] Loading dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MuminDataset(num_nodes=1,625,694, num_relations=2,394,768, size='large', compiled=True, bearer_token_available=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from mumin import MuminDataset\n",
    "\n",
    "# Set file names and paths\n",
    "data_dir = Path(\"data\")\n",
    "dataset_file = \"mumin-large_no-article_image.zip\"\n",
    "\n",
    "# Load the compiled dataset\n",
    "size = \"large\"\n",
    "dataset_path = data_dir.joinpath(dataset_file)\n",
    "include_tweet_images = False\n",
    "include_articles = False\n",
    "dataset = MuminDataset(dataset_path=dataset_path, size=size, include_tweet_images=include_tweet_images, include_articles=include_articles)\n",
    "dataset.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458b32d-f853-44be-be2f-48c9be0d2225",
   "metadata": {},
   "source": [
    "## Join claims with their tweets\n",
    "\n",
    "Since we're focusing on COVID-19 misinformation, we will first filter out the claims that aren't about COVID-19 before joining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c01b304-eb3c-4556-919d-0715c32b76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\320260173.py:7: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  covid_mask = claims.keywords.str.contains('(corona(.*virus)?|covid(.*19)?)') | claims.cluster_keywords.str.contains('(corona(.*virus)?|covid(.*19)?)')\n"
     ]
    }
   ],
   "source": [
    "# Get tweets, claims and the relations between them\n",
    "tweets = dataset.nodes[\"tweet\"].dropna()\n",
    "claims = dataset.nodes[\"claim\"]\n",
    "rels = dataset.rels[(\"tweet\", \"discusses\", \"claim\")]\n",
    "\n",
    "# Filter claims\n",
    "covid_mask = claims.keywords.str.contains('(corona(.*virus)?|covid(.*19)?)') | claims.cluster_keywords.str.contains('(corona(.*virus)?|covid(.*19)?)')\n",
    "claims_filtered = claims.loc[covid_mask, :]\n",
    "\n",
    "# Join tweets and claims on rels\n",
    "tc = (tweets.merge(rels, left_index=True, right_on='src')\n",
    "            .merge(claims_filtered, left_on='tgt', right_index=True)\n",
    "            .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2920030c-59a0-4d6e-8470-19f70e887131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18225 entries, 0 to 18224\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   tweet_id          18225 non-null  uint64        \n",
      " 1   text              18225 non-null  object        \n",
      " 2   created_at        18225 non-null  datetime64[ns]\n",
      " 3   lang              18225 non-null  category      \n",
      " 4   source            18225 non-null  object        \n",
      " 5   num_retweets      18225 non-null  uint64        \n",
      " 6   num_replies       18225 non-null  uint64        \n",
      " 7   num_quote_tweets  18225 non-null  uint64        \n",
      " 8   src               18225 non-null  int64         \n",
      " 9   tgt               18225 non-null  int64         \n",
      " 10  embedding         18225 non-null  object        \n",
      " 11  label             18225 non-null  category      \n",
      " 12  reviewers         18225 non-null  object        \n",
      " 13  date              18225 non-null  datetime64[ns]\n",
      " 14  language          18225 non-null  category      \n",
      " 15  keywords          18225 non-null  object        \n",
      " 16  cluster_keywords  18225 non-null  category      \n",
      " 17  cluster           18225 non-null  category      \n",
      " 18  train_mask        18225 non-null  bool          \n",
      " 19  val_mask          18225 non-null  bool          \n",
      " 20  test_mask         18225 non-null  bool          \n",
      "dtypes: bool(3), category(5), datetime64[ns](2), int64(2), object(5), uint64(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "tc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db063177-f56a-4726-816d-f0e4b42a7ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>num_retweets</th>\n",
       "      <th>num_replies</th>\n",
       "      <th>num_quote_tweets</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>...</th>\n",
       "      <th>label</th>\n",
       "      <th>reviewers</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cluster_keywords</th>\n",
       "      <th>cluster</th>\n",
       "      <th>train_mask</th>\n",
       "      <th>val_mask</th>\n",
       "      <th>test_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1243046281326534661</td>\n",
       "      <td>To keep our upper respiratory tract healthy in...</td>\n",
       "      <td>2020-03-26 05:25:02</td>\n",
       "      <td>en</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243148522209161217</td>\n",
       "      <td>Gargling salt water does not 'kill' coronaviru...</td>\n",
       "      <td>2020-03-26 12:11:18</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1238795119572049920</td>\n",
       "      <td>‡§ï‡•â‡§∞‡•ã‡§®‡§æ ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§´‡•á‡§´‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§§‡•Ä‡§®-‡§ö‡§æ‡§∞ ...</td>\n",
       "      <td>2020-03-14 11:52:26</td>\n",
       "      <td>hi</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1238947475471454220</td>\n",
       "      <td>Antes de llegar a los pulmones dura 4 d√≠as en ...</td>\n",
       "      <td>2020-03-14 21:57:51</td>\n",
       "      <td>es</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239128401115516929</td>\n",
       "      <td>So they say the first symptons are #coughing\\n...</td>\n",
       "      <td>2020-03-15 09:56:47</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>misinformation</td>\n",
       "      <td>[observador.pt]</td>\n",
       "      <td>2020-03-15 12:30:21</td>\n",
       "      <td>pt</td>\n",
       "      <td>corona virus reaching lungs remains</td>\n",
       "      <td>coronavirus china covid 19 treatments recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1243046281326534661  To keep our upper respiratory tract healthy in...   \n",
       "1  1243148522209161217  Gargling salt water does not 'kill' coronaviru...   \n",
       "2  1238795119572049920  ‡§ï‡•â‡§∞‡•ã‡§®‡§æ ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§´‡•á‡§´‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§§‡•Ä‡§®-‡§ö‡§æ‡§∞ ...   \n",
       "3  1238947475471454220  Antes de llegar a los pulmones dura 4 d√≠as en ...   \n",
       "4  1239128401115516929  So they say the first symptons are #coughing\\n...   \n",
       "\n",
       "           created_at lang               source  num_retweets  num_replies  \\\n",
       "0 2020-03-26 05:25:02   en       Hootsuite Inc.            96            6   \n",
       "1 2020-03-26 12:11:18   en   Twitter for iPhone             7            0   \n",
       "2 2020-03-14 11:52:26   hi  Twitter for Android             6            0   \n",
       "3 2020-03-14 21:57:51   es  Twitter for Android             8            3   \n",
       "4 2020-03-15 09:56:47   en  Twitter for Android            10            2   \n",
       "\n",
       "   num_quote_tweets  src  tgt  ...           label        reviewers  \\\n",
       "0                 6    0    0  ...  misinformation  [observador.pt]   \n",
       "1                 0    1    0  ...  misinformation  [observador.pt]   \n",
       "2                 1    2    0  ...  misinformation  [observador.pt]   \n",
       "3                 0    3    0  ...  misinformation  [observador.pt]   \n",
       "4                 1    4    0  ...  misinformation  [observador.pt]   \n",
       "\n",
       "                 date language                             keywords  \\\n",
       "0 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "1 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "2 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "3 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "4 2020-03-15 12:30:21       pt  corona virus reaching lungs remains   \n",
       "\n",
       "                                    cluster_keywords cluster train_mask  \\\n",
       "0  coronavirus china covid 19 treatments recommended       0       True   \n",
       "1  coronavirus china covid 19 treatments recommended       0       True   \n",
       "2  coronavirus china covid 19 treatments recommended       0       True   \n",
       "3  coronavirus china covid 19 treatments recommended       0       True   \n",
       "4  coronavirus china covid 19 treatments recommended       0       True   \n",
       "\n",
       "   val_mask  test_mask  \n",
       "0     False      False  \n",
       "1     False      False  \n",
       "2     False      False  \n",
       "3     False      False  \n",
       "4     False      False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4933b-0b1b-496c-a569-a575f5fad1e5",
   "metadata": {},
   "source": [
    "## Get the necessary features\n",
    "\n",
    "Here we extract the following features:\n",
    "\n",
    "- `text`\n",
    "- `label`\n",
    "- `lang`\n",
    "- `train_mask`\n",
    "- `test_mask`\n",
    "- `val_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87047ad2-265b-4cce-a5ad-ff360a194860",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"text\", \"label\", \"lang\", \"train_mask\", \"test_mask\", \"val_mask\"]\n",
    "dataset_clean = tc[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c675ed-2e76-4e1a-83f1-2cf4b40b4398",
   "metadata": {},
   "source": [
    "# Clean dataset\n",
    "\n",
    "Here we perform only the following operations:\n",
    "\n",
    "- Encode the labels\n",
    "- Substitute URLs, mentions, and (maybe) hashtags with an indicative token\n",
    "- Remove emojis\n",
    "- Normalize whitespace\n",
    "- Remove any other unnecessary characters that I happen to notice\n",
    "\n",
    "All of the more in-depth text cleaning operations will be done once the text has been translated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0591032-42f4-4ba9-99f8-32d0b1bdf2a6",
   "metadata": {},
   "source": [
    "## Encode labels\n",
    "\n",
    "Here we encode the labels in the following way:\n",
    "\n",
    "- `misinformation`: 1\n",
    "- `factual`: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d8cf923-f3eb-4daf-958a-cf9d4954ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\4140734251.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_clean.label.replace(to_replace=encodings, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "encodings = {\"misinformation\": 1, \"factual\": 0}\n",
    "dataset_clean.label.replace(to_replace=encodings, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c684bbf2-2c10-4a81-8139-cdb2946e0f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17625\n",
       "0      600\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ae201-4190-4f8f-a796-a6f2d03984d8",
   "metadata": {},
   "source": [
    "## Remove URLs and mentions\n",
    "\n",
    "Not sure if we should completely remove URLS and mentions as both provide useful information. For now, I'll simply replace URLs with `<URL>` and mentions with `<USER>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1f1e7c4-da7c-4fd5-80dd-8cd44213c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"http\\S+\", \"<URL>\")\n",
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"http\\S+\", \"<URL>\")\n",
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"@\\S+\", \"<USER>\")\n",
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\402204727.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_clean.text = dataset_clean.text.str.replace(\"@\\S+\", \"<USER>\")\n"
     ]
    }
   ],
   "source": [
    "dataset_clean.text = dataset_clean.text.str.replace(\"http\\S+\", \"<URL>\")\n",
    "dataset_clean.text = dataset_clean.text.str.replace(\"@\\S+\", \"<USER>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ffe8eb-21fe-4c72-8dbf-9d07a97a7722",
   "metadata": {},
   "source": [
    "## Remove whitespace literal characters\n",
    "\n",
    "Here we remove stray newline and tab characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15bd34e9-ac42-4cb9-95c1-fb569975fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\AppData\\Local\\Temp\\ipykernel_17372\\876289396.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_test = dataset_clean.text.str.replace(r\"\\n|\\t\", \"\").str.replace(\"|\", \"\", regex=False).str.replace(\"\\s+\", \" \")\n"
     ]
    }
   ],
   "source": [
    "text_test = dataset_clean.text.str.replace(r\"\\n|\\t\", \"\").str.replace(\"|\", \"\", regex=False).str.replace(\"\\s+\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29fa2bcb-6384-4c92-9005-7287f3c23f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"To keep our upper respiratory tract healthy in this time of #coronavirus, let's all gargle warm water with salt (preferably himalayan or sea salt), some ginger and apple cider vinegar first thing in the morning and before we sleep. Spit the water out after. #LetsFightCovid19 <URL>\",\n",
       " \"Gargling salt water does not 'kill' coronavirus in your throat Metro News <URL>\",\n",
       " '‡§ï‡•â‡§∞‡•ã‡§®‡§æ ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§´‡•á‡§´‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§§‡•Ä‡§®-‡§ö‡§æ‡§∞ ‡§¶‡§ø‡§® ‡§§‡§ï ‡§ó‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§π‡•à...‡§â‡§∏‡§∏‡•á ‡§ñ‡§æ‡§Ç‡§∏‡•Ä ‡§µ ‡§ï‡§´ ‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§≠‡•Ä ‡§∞‡§π‡§§‡•Ä ‡§π‡•à...‡§ê‡§∏‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§Ö‡§ó‡§∞ ‡§ó‡§∞‡•ç‡§Æ ‡§™‡§æ‡§®‡•Ä ‡§Æ‡•á‡§Ç ‡§®‡§Æ‡§ï ‡§°‡§æ‡§≤‡§ï‡§∞ ‡§ó‡§∞‡§æ‡§∞‡•á ‡§ï‡§ø‡§è ‡§ú‡§æ‡§è‡§Ç...‡§î‡§∞ ‡§®‡•Ä‡§Ç‡§¨‡•Ç ‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§è ‡§§‡•ã ‡§á‡§∏ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§¨‡§ö‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à...‡§î‡§∞ ‡§Ö‡§®‡•á‡§ï‡•ã‡§Ç ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä ‡§¨‡§ö ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§üïâÔ∏èüëãüå∑üåπüíêüå¥ <URL>',\n",
       " 'Antes de llegar a los pulmones dura 4 d√≠as en la garganta, en ese punto la persona infectadas empiezan a toser y a tener dolor de garganta. Deben tomar mucha agua y hacer g√°rgaras de agua tibia con sal o vinagre esto eliminar√° el CORONAVIRUS retuitear pues pueden salvar alguien. <URL>',\n",
       " 'So they say the first symptons are #coughingThe virus stays in your throat for 4 days and that you can kill it by drinking hot liquids.. Tea, soup etc#coronavirus #COVID„Éº19 <URL>']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test.to_list()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8f689-3b7b-49df-8677-fe5d2f438631",
   "metadata": {},
   "source": [
    "## Remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c85062-5916-4417-9e3e-5905d412f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = dataset_clean.text.str.encode(\"ascii\", \"ignore\").str.decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6515bbd-b72b-46e7-80b3-dcaae4fbaedc",
   "metadata": {},
   "source": [
    "## Remove other unnecessary characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b807b-1180-4156-a6d3-0970793fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.text = dataset_clean.text.str.replace(\"|\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a046cc5-a5a2-455c-bc47-109aae59d027",
   "metadata": {},
   "source": [
    "## Remove excess whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680cc83-918c-47f1-bec7-06b00d51062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.text = dataset_clean.text.str.replace(\"\\s+\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b236ba-379c-423d-8cab-e774eda67e95",
   "metadata": {},
   "source": [
    "# Translate text\n",
    "\n",
    "This will be done later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af965b-f89d-4eba-94dd-1ea4582ccfc8",
   "metadata": {},
   "source": [
    "# Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "949588cb-e0f0-465b-a965-aa25f44c22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits\n",
    "train = dataset_clean.query('train_mask == True')\n",
    "val = dataset_clean.query('val_mask == True')\n",
    "test = dataset_clean.query('test_mask == True')\n",
    "\n",
    "# Write them to csv files\n",
    "features = [\"text\", \"label\", \"lang\"]\n",
    "output_files = [\"mumin_large-train.csv\", \"mumin_large-test.csv\", \"mumin_large-validation.csv\"]\n",
    "splits = [train, test, val]\n",
    "for split, output_file in zip(splits, output_files):\n",
    "    split.to_csv(data_dir.joinpath(output_file), columns=features, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml-general')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6360599b59dc8f487e15f687f1f2f61281c019cf0eac6cd68d9a3c330f29f67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
